{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common import *\n",
    "# https://www.kaggle.com/vatsalmavani/shopee-training-eff-b4/data?select=engine.py\n",
    "import sys\n",
    "sys.path.append('../data/pytorch-image-models')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/train_images'\n",
    "# TRAIN_CSV = '../input/utils-shopee/folds.csv'\n",
    "TRAIN_CSV = '../data/train.csv'\n",
    "MODEL_PATH = '../cache/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "def get_train_transforms(img_size=512):\n",
    "    return albumentations.Compose([\n",
    "        albumentations.Resize(img_size, img_size, always_apply=True),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(limit=120, p=0.8),\n",
    "        albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "        albumentations.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])\n",
    "\n",
    "def get_valid_transforms(img_size=512):\n",
    "\n",
    "    return albumentations.Compose([\n",
    "        albumentations.Resize(img_size, img_size, always_apply=True),\n",
    "        albumentations.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "class ShopeeScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, lr_start=5e-6, lr_max=1e-5,\n",
    "                 lr_min=1e-6, lr_ramp_ep=5, lr_sus_ep=0, lr_decay=0.4,\n",
    "                 last_epoch=-1):\n",
    "        self.lr_start = lr_start\n",
    "        self.lr_max = lr_max\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_ramp_ep = lr_ramp_ep\n",
    "        self.lr_sus_ep = lr_sus_ep\n",
    "        self.lr_decay = lr_decay\n",
    "        super(ShopeeScheduler, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\", UserWarning)\n",
    "        if self.last_epoch == 0:\n",
    "            self.last_epoch += 1\n",
    "            return [self.lr_start for _ in self.optimizer.param_groups]\n",
    "        lr = self._compute_lr_from_epoch()\n",
    "        self.last_epoch += 1\n",
    "        return [lr for _ in self.optimizer.param_groups]\n",
    "    \n",
    "    def _get_closed_form_lr(self):\n",
    "        return self.base_lrs\n",
    "    \n",
    "    def _compute_lr_from_epoch(self):\n",
    "        if self.last_epoch < self.lr_ramp_ep:\n",
    "            lr = ((self.lr_max - self.lr_start) / \n",
    "                  self.lr_ramp_ep * self.last_epoch + \n",
    "                  self.lr_start)\n",
    "        elif self.last_epoch < self.lr_ramp_ep + self.lr_sus_ep:\n",
    "            lr = self.lr_max\n",
    "        else:\n",
    "            lr = ((self.lr_max - self.lr_min) * self.lr_decay**\n",
    "                  (self.last_epoch - self.lr_ramp_ep - self.lr_sus_ep) + \n",
    "                  self.lr_min)\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class ShopDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        label = row.label_group\n",
    "\n",
    "        img_path = os.path.join(self.root_dir, row.image)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return {\n",
    "            'image' : image,\n",
    "            'label' : torch.tensor(label).long()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_fn(model, data_loader, optimizer, scheduler, epoch, device):\n",
    "    model.train()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(data_loader, desc = \"Training epoch: \" + str(epoch+1))\n",
    "\n",
    "    for t,data in enumerate(tk):\n",
    "        optimizer.zero_grad()\n",
    "        for k,v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "\n",
    "        _, loss = model(**data)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        fin_loss += loss.item() \n",
    "\n",
    "        tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1)), 'LR' : optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    scheduler.step()\n",
    "    return fin_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def eval_fn(model, data_loader, epoch, device):\n",
    "    model.eval()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(data_loader, desc = \"Validation epoch: \" + str(epoch+1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t,data in enumerate(tk):\n",
    "            for k,v in data.items():\n",
    "                data[k] = v.to(device)\n",
    "\n",
    "            _, loss = model(**data)\n",
    "            fin_loss += loss.item() \n",
    "            tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1))})\n",
    "        return fin_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 54\n",
    "#     img_size = 512\n",
    "    img_size = 128\n",
    "    classes = 11014\n",
    "    scale = 30\n",
    "    margin = 0.5\n",
    "    fc_dim = 512\n",
    "    epochs = 15\n",
    "    batch_size = 4\n",
    "    num_workers = 8\n",
    "#     model_name = 'efficientnet_b3'\n",
    "#     model_name = 'tf_efficientnet_b4'\n",
    "#     model_name = 'tf_efficientnet_b2'\n",
    "#     model_name = 'eca_nfnet_l1'\n",
    "    model_name = 'dm_nfnet_f5'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    scheduler_params = {\n",
    "        \"lr_start\": 1e-5,\n",
    "        \"lr_max\": 1e-5 * batch_size,     # 1e-5 * 32 (if batch_size(=32) is different then)\n",
    "        \"lr_min\": 1e-6,\n",
    "        \"lr_ramp_ep\": 5,\n",
    "        \"lr_sus_ep\": 0,\n",
    "        \"lr_decay\": 0.8,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del backbone\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = timm.create_model(CFG.model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone.head.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "    \n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "        return output, nn.CrossEntropyLoss()(output,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name,\n",
    "        fc_dim = CFG.fc_dim,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = True):\n",
    "\n",
    "        super(ShopModel,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.model_name = model_name\n",
    "        if model_name == 'eca_nfnet_l1':\n",
    "            in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "        elif model_name == 'dm_nfnet_f5':\n",
    "            in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "        else:\n",
    "            in_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.1)\n",
    "            \n",
    "            \n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            if model_name == 'eca_nfnet_l1':\n",
    "                self.fc = nn.Linear(in_features, fc_dim)\n",
    "                self._init_params2()\n",
    "            elif model_name == 'dm_nfnet_f5':\n",
    "                self.fc = nn.Linear(in_features, fc_dim)\n",
    "                self._init_params2()\n",
    "            else:\n",
    "                self.classifier = nn.Linear(in_features, fc_dim)\n",
    "                self._init_params()\n",
    "            in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "        \n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "    def _init_params2(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        features = self.extract_features(image)\n",
    "        if self.training:\n",
    "            logits = self.final(features, label)\n",
    "            return logits\n",
    "        else:\n",
    "            return features\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc and self.training:\n",
    "            x = self.dropout(x)\n",
    "            if self.model_name == 'eca_nfnet_l1':\n",
    "                x = self.fc(x)\n",
    "            elif self.model_name == 'dm_nfnet_f5':\n",
    "                x = self.fc(x)\n",
    "            else:\n",
    "                x = self.classifier(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    \n",
    "    df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "    labelencoder= LabelEncoder()\n",
    "    df['label_group'] = labelencoder.fit_transform(df['label_group'])\n",
    "\n",
    "    trainset = ShopDataset(df,\n",
    "                             DATA_DIR,\n",
    "                             transform = get_train_transforms(img_size = CFG.img_size))\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size = CFG.batch_size,\n",
    "        num_workers = CFG.num_workers,\n",
    "        pin_memory = True,\n",
    "        shuffle = True,\n",
    "        drop_last = True\n",
    "    )\n",
    "\n",
    "    model = ShopModel()\n",
    "    model.to(CFG.device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr = CFG.scheduler_params['lr_start'])\n",
    "    scheduler = ShopeeScheduler(optimizer, **CFG.scheduler_params)\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        avg_loss_train = train_fn(model, trainloader, optimizer, scheduler, epoch, CFG.device)\n",
    "        torch.save(model.state_dict(), MODEL_PATH + 'ashish_arcface_512x512_{}_{}_epochs.pt'.format(CFG.model_name, CFG.epochs))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "            },\n",
    "            MODEL_PATH + 'arcface_512x512_{}_{}_epochs_checkpoints.pt'.format(CFG.model_name, CFG.epochs)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for dm_nfnet_f5 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1: 100%|██████████| 8562/8562 [1:29:21<00:00,  1.60it/s, loss=24.021918, LR=1e-5]\n",
      "Training epoch: 2: 100%|██████████| 8562/8562 [1:31:17<00:00,  1.56it/s, loss=23.768663, LR=2.2e-5]\n",
      "Training epoch: 3: 100%|██████████| 8562/8562 [1:30:15<00:00,  1.58it/s, loss=21.573717, LR=3.4e-5]\n",
      "Training epoch: 4: 100%|██████████| 8562/8562 [1:26:08<00:00,  1.66it/s, loss=16.900341, LR=3.22e-5]\n",
      "Training epoch: 5: 100%|██████████| 8562/8562 [1:24:41<00:00,  1.68it/s, loss=16.474169, LR=2.1e-5]\n",
      "Training epoch: 6: 100%|██████████| 8562/8562 [1:24:54<00:00,  1.68it/s, loss=16.338650, LR=1.38e-5]\n",
      "Training epoch: 7: 100%|██████████| 8562/8562 [1:24:45<00:00,  1.68it/s, loss=16.327169, LR=9.18e-6]\n",
      "Training epoch: 8: 100%|██████████| 8562/8562 [1:24:35<00:00,  1.69it/s, loss=16.323214, LR=6.23e-6]\n",
      "Training epoch: 9: 100%|██████████| 8562/8562 [1:24:52<00:00,  1.68it/s, loss=16.312222, LR=4.35e-6]\n",
      "Training epoch: 10: 100%|██████████| 8562/8562 [1:24:13<00:00,  1.69it/s, loss=nan, LR=3.14e-6]      \n",
      "Training epoch: 11: 100%|██████████| 8562/8562 [1:24:04<00:00,  1.70it/s, loss=nan, LR=2.37e-6]\n",
      "Training epoch: 12: 100%|██████████| 8562/8562 [1:24:07<00:00,  1.70it/s, loss=nan, LR=1.88e-6]\n",
      "Training epoch: 13: 100%|██████████| 8562/8562 [1:24:05<00:00,  1.70it/s, loss=nan, LR=1.56e-6]\n",
      "Training epoch: 14: 100%|██████████| 8562/8562 [1:24:04<00:00,  1.70it/s, loss=nan, LR=1.36e-6]\n",
      "Training epoch: 15: 100%|██████████| 8562/8562 [1:24:08<00:00,  1.70it/s, loss=nan, LR=1.23e-6]\n"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  9 08:10:18 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 51%   62C    P8    16W / 250W |  10861MiB / 11175MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2442      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      3223      G   /usr/bin/gnome-shell               70MiB |\r\n",
      "|    0   N/A  N/A      6956      G   /usr/lib/xorg/Xorg                172MiB |\r\n",
      "|    0   N/A  N/A      7127      G   /usr/bin/gnome-shell               25MiB |\r\n",
      "|    0   N/A  N/A      7575      G   ...token=3536807086926714895       19MiB |\r\n",
      "|    0   N/A  N/A     12560      C   ...nvs/shoprapids/bin/python    10547MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shoprapids",
   "language": "python",
   "name": "shoprapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
