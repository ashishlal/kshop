{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc48fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/moeinshariatnia/indonesian-distilbert-finetuning-with-arcmargin\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import (BertTokenizer, BertModel,\n",
    "                          DistilBertTokenizer, DistilBertModel)\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2d6e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f12d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN words: 1, MAX words: 61\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_lengths = df_train['title'].apply(lambda x: len(x.split(\" \"))).to_numpy()\n",
    "print(f\"MIN words: {title_lengths.min()}, MAX words: {title_lengths.max()}\")\n",
    "plt.hist(title_lengths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0541ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DistilBERT = True # if set to False, BERT model will be used\n",
    "    bert_hidden_size = 768\n",
    "    \n",
    "    batch_size = 64\n",
    "    epochs = 30\n",
    "    num_workers = 4\n",
    "    learning_rate = 3e-5 #3e-5\n",
    "    scheduler = \"ReduceLROnPlateau\"\n",
    "    step = 'epoch'\n",
    "    patience = 2\n",
    "    factor = 0.8\n",
    "    dropout = 0.5\n",
    "    model_path = \"../cache\"\n",
    "#     model_name = \"/home/watts/lal/Kaggle/kshop/msmarco-distilbert-base-dot-prod-v3\"\n",
    "    model_name = \"/home/watts/lal/Kaggle/kshop/msmarco-distilbert-base-dot-prod-v3\"\n",
    "    max_length = 70\n",
    "    model_save_name = \"text_model_stsb_distilbert_base.pt\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7a5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CFG.DistilBERT:\n",
    "#     model_name='cahya/distilbert-base-indonesian'\n",
    "#     tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "#     bert_model = DistilBertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b5a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "\n",
    "# Queries we want embeddings for\n",
    "queries = ['What is the capital of France?', 'How many people live in New York City?']\n",
    "\n",
    "# Passages that provide answers\n",
    "passages = ['Paris is the capital of France', 'New York City is the most populous city in the United States, with an estimated 8,336,817 people living in the city, according to U.S. Census estimates dating July 1, 2019']\n",
    "\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "distilbert_model = AutoModel.from_pretrained(CFG.model_name).to('cuda')\n",
    "\n",
    "def compute_embeddings(sentences):\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "    #Compute query embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = distilbert_model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    return mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98addd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(queries, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959ab75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2003, 1996, 3007, 1997, 2605, 1029,  102,    0,    0],\n",
       "        [ 101, 2129, 2116, 2111, 2444, 1999, 2047, 2259, 2103, 1029,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10762249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 768]), torch.Size([2, 768]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = compute_embeddings(queries)\n",
    "passage_embeddings = compute_embeddings(passages)\n",
    "query_embeddings.shape, passage_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7c1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "df_train['label_code'] = lbl_encoder.fit_transform(df_train['label_group'])\n",
    "NUM_CLASSES = df_train['label_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a416153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, mode=\"train\", max_length=None):\n",
    "        self.dataframe = dataframe\n",
    "        if mode != \"test\":\n",
    "            self.targets = dataframe['label_code'].values\n",
    "        titles_1 = dataframe.title.values\n",
    "        titles_1 = [s.replace('(', '') for s in titles_1]\n",
    "        titles_1 = [s.replace(')', '') for s in titles_1]\n",
    "        titles_1 = [s.replace('[', '') for s in titles_1]\n",
    "\n",
    "        import re\n",
    "        titles_1 = [s.replace('\\\\\\\\', '\\\\') for s in titles_1]\n",
    "        titles_1 = [re.sub(r'\\\\x[0-f]{2}',r'', s) for s in titles_1]\n",
    "        titles_1 = [s.replace('b\"', '') for s in titles_1]\n",
    "        titles_1 = [s.replace('\"', '') for s in titles_1]\n",
    "        dataframe['title'] = titles_1\n",
    "        texts = list(dataframe['title'].apply(lambda o: str(o)).values)\n",
    "        self.encodings = tokenizer(texts, \n",
    "                                   padding=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=max_length,\n",
    "                                   return_tensors='pt')\n",
    "        self.mode = mode\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # putting each tensor in front of the corresponding key from the tokenizer\n",
    "        # HuggingFace tokenizers give you whatever you need to feed to the corresponding model\n",
    "        item = {key: torch.tensor(values[idx]) for key, values in self.encodings.items()}\n",
    "        # when testing, there are no targets so we won't do the following\n",
    "        if self.mode != \"test\":\n",
    "            item['labels'] = torch.tensor(self.targets[idx]).long()\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c012d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 70]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataset = TextDataset(df_train, tokenizer, max_length=CFG.max_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=CFG.batch_size, \n",
    "                                         num_workers=CFG.num_workers, \n",
    "                                         shuffle=True)\n",
    "batch = next(iter(dataloader))\n",
    "print(batch['input_ids'].shape, batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ef222ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2192,  4886,  ...,     0,     0,     0],\n",
       "         [  101, 14925, 23169,  ...,     0,     0,     0],\n",
       "         [  101, 16516,  8521,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  7279, 20009,  ...,     0,     0,     0],\n",
       "         [  101, 21368,  2072,  ...,     0,     0,     0],\n",
       "         [  101,  5472,  2389,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([ 8320,  8448,  5423, 10122,  8762,   931,  3791,  4345,  1032,  2171,\n",
       "          8643,  1800,  4103,  9272,  9031,  2871,  7551,  2189,  8967,  7738,\n",
       "          2090,  6747, 10632,  9476,  8547,  6940,  6432, 10977, 10763,  6876,\n",
       "          6514,  1817,  5792,  8565,  2147,  7016,    54,  1452,  8639,  5540,\n",
       "          3266,  1884,  9872,  6022,  1735,  3893,  7964,  4353,  4873,  2062,\n",
       "          2015,   455, 10086,  9749,  5026,  7198,  1876,  2147, 10654,  6395,\n",
       "          2614,  4642,  6860,  4949])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781f4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/ronghuaiyang/arcface-pytorch/blob/47ace80b128042cd8d2efd408f55c5a3e156b032/models/metrics.py#L10\n",
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        \n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        output *= self.s\n",
    "        # print(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15cc34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert_model, \n",
    "                 num_classes=NUM_CLASSES, \n",
    "                 last_hidden_size=CFG.bert_hidden_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.arc_margin = ArcMarginProduct(last_hidden_size, \n",
    "                                           num_classes, \n",
    "                                           s=30.0, \n",
    "                                           m=0.50, \n",
    "                                           easy_margin=False)\n",
    "        self.batch = {}\n",
    "    \n",
    "    def my_mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def my_compute_embeddings(self, batch):\n",
    "        #Tokenize sentences\n",
    "#         encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "        #Compute query embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = self.bert_model(**batch)\n",
    "\n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        return self.my_mean_pooling(model_output, batch['attention_mask'])\n",
    "    def get_bert_features(self, batch):\n",
    "        self.batch['input_ids'] = batch['input_ids']\n",
    "        self.batch['attention_mask'] = batch['attention_mask']\n",
    "        CLS_token_state  = self.my_compute_embeddings(self.batch)\n",
    "#         output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "#         last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n",
    "#         CLS_token_state = last_hidden_state[:, 0, :] # obtaining CLS token state which is the first token.\n",
    "        return CLS_token_state\n",
    "    \n",
    "    def get_bert_features2(self, batch):\n",
    "        x = self.bert_model(input_ids=batch['input_ids'],attention_mask=batch['attention_mask'])\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        CLS_hidden_state = self.get_bert_features(batch)\n",
    "#         print(CLS_hidden_state)\n",
    "        output = self.arc_margin(CLS_hidden_state, batch['labels'])\n",
    "#         print(CLS_hidden_state)\n",
    "        return CLS_hidden_state, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fecaa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert_model, \n",
    "                 num_classes=NUM_CLASSES, \n",
    "                 last_hidden_size=CFG.bert_hidden_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.arc_margin = ArcMarginProduct(last_hidden_size, \n",
    "                                           num_classes, \n",
    "                                           s=30.0, \n",
    "                                           m=0.50, \n",
    "                                           easy_margin=False)\n",
    "        self.batch = {}\n",
    "    \n",
    "    def my_mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def my_compute_embeddings(self, batch):\n",
    "        #Tokenize sentences\n",
    "#         encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "        #Compute query embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = self.bert_model(**batch)\n",
    "\n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        return self.my_mean_pooling(model_output, batch['attention_mask'])\n",
    "    def get_bert_features(self, batch):\n",
    "        self.batch['input_ids'] = batch['input_ids']\n",
    "        self.batch['attention_mask'] = batch['attention_mask']\n",
    "        CLS_token_state  = self.my_compute_embeddings(self.batch)\n",
    "#         output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "#         last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n",
    "#         CLS_token_state = last_hidden_state[:, 0, :] # obtaining CLS token state which is the first token.\n",
    "        return CLS_token_state\n",
    "    \n",
    "    def get_bert_features2(self, batch):\n",
    "        x = self.bert_model(input_ids=batch['input_ids'],attention_mask=batch['attention_mask'])\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "        return features\n",
    "    def forward(self, batch):\n",
    "        CLS_hidden_state = self.get_bert_features2(batch)\n",
    "#         print(CLS_hidden_state)\n",
    "        output = self.arc_margin(CLS_hidden_state, batch['labels'])\n",
    "#         print(CLS_hidden_state)\n",
    "        return F.normalize(CLS_hidden_state), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a554a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgMeter:\n",
    "    def __init__(self, name=\"Metric\"):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg, self.sum, self.count = [0]*3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += val * count\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "    def __repr__(self):\n",
    "        text = f\"{self.name}: {self.avg:.4f}\"\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2030282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(model, \n",
    "              criterion, \n",
    "              loader,\n",
    "              optimizer=None, \n",
    "              lr_scheduler=None, \n",
    "              mode=\"train\", \n",
    "              step=\"batch\"):\n",
    "    \n",
    "    loss_meter = AvgMeter()\n",
    "    acc_meter = AvgMeter()\n",
    "    \n",
    "    tqdm_object = tqdm(loader, total=len(loader))\n",
    "    for batch in tqdm_object:\n",
    "        batch = {k: v.to(CFG.device) for k, v in batch.items()}\n",
    "        _, preds = model(batch)\n",
    "        loss = criterion(preds, batch['labels'])\n",
    "        if mode == \"train\":\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step == \"batch\":\n",
    "                lr_scheduler.step()\n",
    "                \n",
    "        count = batch['input_ids'].size(0)\n",
    "        loss_meter.update(loss.item(), count)\n",
    "        \n",
    "        accuracy = get_accuracy(preds.detach(), batch['labels'])\n",
    "        acc_meter.update(accuracy.item(), count)\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            tqdm_object.set_postfix(train_loss=loss_meter.avg, accuracy=acc_meter.avg, lr=get_lr(optimizer))\n",
    "        else:\n",
    "            tqdm_object.set_postfix(valid_loss=loss_meter.avg, accuracy=acc_meter.avg)\n",
    "    \n",
    "    return loss_meter, acc_meter\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "def get_accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    preds shape: (batch_size, num_labels)\n",
    "    targets shape: (batch_size)\n",
    "    \"\"\"\n",
    "    preds = preds.argmax(dim=1)\n",
    "    acc = (preds == targets).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ce60a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(epochs, model, train_loader, valid_loader, \n",
    "               criterion, optimizer, lr_scheduler=None):\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"*\" * 30)\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        current_lr = get_lr(optimizer)\n",
    "        \n",
    "        model.train()\n",
    "        train_loss, train_acc = one_epoch(model, \n",
    "                                          criterion, \n",
    "                                          train_loader, \n",
    "                                          optimizer=optimizer,\n",
    "                                          lr_scheduler=lr_scheduler,\n",
    "                                          mode=\"train\",\n",
    "                                          step=CFG.step)                     \n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             valid_loss, valid_acc = one_epoch(model, \n",
    "#                                               criterion, \n",
    "#                                               valid_loader, \n",
    "#                                               optimizer=None,\n",
    "#                                               lr_scheduler=None,\n",
    "#                                               mode=\"valid\")\n",
    "        \n",
    "#         if valid_loss.avg < best_loss:\n",
    "#             best_loss = valid_loss.avg\n",
    "#             best_model_weights = copy.deepcopy(model.state_dict())\n",
    "#             torch.save(model.state_dict(), f'{CFG.model_path}/{CFG.model_save_name}')\n",
    "#             print(\"Saved best model!\")\n",
    "        torch.save(model.state_dict(), f'{CFG.model_path}/{CFG.model_save_name}')\n",
    "        print(\"Saved model!\")\n",
    "        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "#             lr_scheduler.step(valid_loss.avg)\n",
    "            lr_scheduler.step(train_loss.avg)\n",
    "            if current_lr != get_lr(optimizer):\n",
    "                print(\"Loading best model weights!\")\n",
    "                model.load_state_dict(torch.load(f'{CFG.model_path}/{CFG.model_save_name}', \n",
    "                                                 map_location=CFG.device))\n",
    "        \n",
    "        print(\"*\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63fd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(df_train, tokenizer, max_length=CFG.max_length)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=CFG.batch_size, \n",
    "                                           num_workers=CFG.num_workers, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6188fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(epochs, model, train_loader, valid_loader, \n",
    "               criterion, optimizer, lr_scheduler=None):\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"*\" * 30)\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        current_lr = get_lr(optimizer)\n",
    "        \n",
    "        model.train()\n",
    "        train_loss, train_acc = one_epoch(model, \n",
    "                                          criterion, \n",
    "                                          train_loader, \n",
    "                                          optimizer=optimizer,\n",
    "                                          lr_scheduler=lr_scheduler,\n",
    "                                          mode=\"train\",\n",
    "                                          step=CFG.step)                     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_acc = one_epoch(model, \n",
    "                                              criterion, \n",
    "                                              valid_loader, \n",
    "                                              optimizer=None,\n",
    "                                              lr_scheduler=None,\n",
    "                                              mode=\"valid\")\n",
    "        \n",
    "        if valid_loss.avg < best_loss:\n",
    "            best_loss = valid_loss.avg\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), f'{CFG.model_path}/{CFG.model_save_name}')\n",
    "            print(\"Saved best model!\")\n",
    "#         torch.save(model.state_dict(), f'{CFG.model_path}/{CFG.model_save_name}')\n",
    "#         print(\"Saved model!\")\n",
    "        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            lr_scheduler.step(valid_loss.avg)\n",
    "#             lr_scheduler.step(train_loss.avg)\n",
    "            if current_lr != get_lr(optimizer):\n",
    "                print(\"Loading best model weights!\")\n",
    "                model.load_state_dict(torch.load(f'{CFG.model_path}/{CFG.model_save_name}', \n",
    "                                                 map_location=CFG.device))\n",
    "        \n",
    "        print(\"*\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06efb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(df_train, \n",
    "                                      test_size=0.33, \n",
    "                                      shuffle=True, \n",
    "                                      random_state=42, \n",
    "                                      stratify=df_train['label_code'])\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer, max_length=CFG.max_length)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=CFG.batch_size, \n",
    "                                           num_workers=CFG.num_workers, \n",
    "                                           shuffle=True)\n",
    "valid_dataset = TextDataset(valid_df, tokenizer, max_length=CFG.max_length)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                                           batch_size=CFG.batch_size, \n",
    "                                           num_workers=CFG.num_workers, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3856278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model2(distilbert_model).to(CFG.device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG.learning_rate)\n",
    "if CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                              mode=\"min\", \n",
    "                                                              factor=CFG.factor, \n",
    "                                                              patience=CFG.patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f802ee82feb342bd85bf965f6c6db24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516eed165c4a40bbb76030d192a503ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8014dcf63074603aa623bf2ed16b010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cf28e40ec54296a4333cd574b62cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd81b5c63bb0496099983c4ff0b99fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcba9c8d1ceb49d489d3bae68ad8645c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365995e245640feb6f21e0372d62ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2548953b1e740c38a666fcb7eaa4d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69de47e4e95d4df4a9397f8992f5c510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "train_eval(CFG.epochs, model, train_loader, None,\n",
    "           criterion, optimizer, lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ec48b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7503fb12bd4c44895151be03f70858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59afda8dacae48d4a90fe2bb730647c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9af9a150ba441f9c14036e6469c403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a5b7c7450e43c7a2c44e69375fcadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e3aa487f3945f488dd23bc94791b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8081027abec146449f66bbe694256652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4462529192a45e788980d80bb259507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b208d0b30c4a68b4a2a0404970afd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d548249ad9c04bbc8d52d82808c11270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9252c016614b54862911e380c3dd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7700026e6f4042509c7078f84d234778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f07de4decc40139ff6a3c8cd58e629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52b57521f91467bb2532a3e8242dfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ae03da21e04f76a189dc0b3897913f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e4c6cfcf0a4444a048f189ffffe624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a95e552bae4451bbfb17b13aca129b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5fdc974c4747a6ac4af5e7f7ada738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1258c7f4990e49428a4b48d6a58cf45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052c66cff9504ea5a77b591613cd2e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0682477da4e46a68c73ed21b1468729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc83d74bd9cd49f9bfa0c9e450c9c6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dd3f3d709e447296d3d17201b00209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915c3de6c6ba4d16aa261c8eed07181e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64c7c9033404bee8024882d7bdb403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9fc36bec64405086334ce21ba8b7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4186469028e4d22b74e60b7aeaa0185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2e168b5e82482a9e4c40b6548514da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf6a47729764c2fbd64ff1cc2f73d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a32b25dd8747ab96d87a825cc5c5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3b8f2a84cb43a28b8d7793444619ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c35ee027ba242528a33ddde17b06742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612e58874ce04db58a8bf7dba84d596e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc5b2b4d2f94ffd87a2f3abddf1e9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9794967a684a18a93b3b4299cc0f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7da9d007e04cedb767af9c0cb475c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc3cf2cf9d4423a9f63938eb9767a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b5b1a6ddc0410faa1105787014b296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaedabe4c9441dfb06c3cce6874cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e12c3546004aa1a5f10a422f53479f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8015346130234c79b60b1a276a812736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e13b2b9f924917ac33c599681929cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2871d671a4aa4ccbb59e5ec891c3c197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa8b4b3583941ed8837247c326c23ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb19ea677c8040dab72101e1ebbdcea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3555fabac20b4366ad94a49fdc33cb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1b3621f4364e46a9d4c21d9ec45f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5482eb28faaf4ec2980ba46a40541463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf2434aea5546f793f1cdd8ee4c7acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b847295d3d9e4065857b4e11be5c4b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e95e1e9da01496bb29cd30c7d12a51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4da73100d484855b540c27563656dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f1d4efe7674c599ede3a8b1c325924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21874a249e3544e1bcc67316259c95a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ec9ff59d9042a082eeea67c83e3a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eaa1bb34314899b7c3306ab3468cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bf9c8c152c4ea5ab6a5e648c696748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea8b81574aa4737bb6e72951e11bc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba9ca290e1346b5bc7a9e8b9e6d9637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b4054c43124396bf682f10dee1fec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b7c50754cf42ce8e19f5d2cf749e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885ab841cad54813bdd8fcf76aa2b359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0c6e1b047a49f08d8b11cb9cb02af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c0fa17032c492b86f8c8fe5fa8ed98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a21e772d0cd4d979dc9d18f28f4cdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67420dee32a4bdc88a7ac99c4a46519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5d472e3f164b7a91796d8ac7ca0b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7c3eae36a84bdf9d902d6ab9b048f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc647dfc87f24bf18d171d1e6f3f1fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "******************************\n",
      "******************************\n",
      "Epoch 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00e9302c7404850aaa14a7a96f5a0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b64bd2e671b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_eval(CFG.epochs, model, train_loader, valid_loader,\n\u001b[0;32m----> 2\u001b[0;31m            criterion, optimizer, lr_scheduler=lr_scheduler)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-a626d08abb14>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(epochs, model, train_loader, valid_loader, criterion, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                           \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                           step=CFG.step)                     \n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-09765c24719c>\u001b[0m in \u001b[0;36mone_epoch\u001b[0;34m(model, criterion, loader, optimizer, lr_scheduler, mode, step)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shoprapids/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shoprapids/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_eval(CFG.epochs, model, train_loader, valid_loader,\n",
    "           criterion, optimizer, lr_scheduler=lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2692a9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../cache/stsb_distilbert_base_tokenizer2/tokenizer_config.json',\n",
       " '../cache/stsb_distilbert_base_tokenizer2/special_tokens_map.json',\n",
       " '../cache/stsb_distilbert_base_tokenizer2/vocab.txt',\n",
       " '../cache/stsb_distilbert_base_tokenizer2/added_tokens.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.save_pretrained(\"../cache/stsb_distilbert_base_tokenizer2\")\n",
    "# torch.save(model.state_dict(), \"../cache/stsb_distilbert_base_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1075dae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.from_pretrained(\"../cache/stsb_distilbert_base_tokenizer\")\n",
    "# model.load_state_dict(torch.load(\"../cache/stsb_distilbert_base_final.pt\"))\n",
    "# model.load_state_dict(torch.load(\"../cache/text_model.pt\"))\n",
    "model.load_state_dict(torch.load(f'{CFG.model_path}/{CFG.model_save_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcfa813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "# df_train = pd.read_csv(DATA_DIR+'/train.csv')\n",
    "titles_1 = df_train.title.values\n",
    "titles_1 = [s.replace('(', '') for s in titles_1]\n",
    "titles_1 = [s.replace(')', '') for s in titles_1]\n",
    "titles_1 = [s.replace('[', '') for s in titles_1]\n",
    "\n",
    "import re\n",
    "titles_1 = [s.replace('\\\\\\\\', '\\\\') for s in titles_1]\n",
    "titles_1 = [re.sub(r'\\\\x[0-f]{2}',r'', s) for s in titles_1]\n",
    "titles_1 = [s.replace('b\"', '') for s in titles_1]\n",
    "titles_1 = [s.replace('\"', '') for s in titles_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff5e1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9561a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings4(model, tokenizer, embeddings):\n",
    "    N = int(np.ceil(df_train.shape[0]/100))\n",
    "    L = 100\n",
    "    df = titles_1\n",
    "    max_len = 70\n",
    "    model.eval()\n",
    "    for ii in tqdm(range(N)):\n",
    "    #     if ii != 0:\n",
    "    #         continue\n",
    "    #     if ii  < N-1:\n",
    "    #         continue\n",
    "\n",
    "        if ii != N-1:\n",
    "            batch_1 = df[ii*L:(ii+1)*L]\n",
    "        else:\n",
    "            batch_1 = df[(N-1)*L:]\n",
    "    #     print(L, len(batch_1))\n",
    "    #     print(batch_1)\n",
    "    #     tokenized = batch_1['title'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "        tokenized = [tokenizer(x, padding=True, truncation=True, max_length=70, return_tensors='pt') for x in batch_1]\n",
    "#         tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in batch_1]\n",
    "        \n",
    "        for j, token in enumerate(tokenized):\n",
    "            with torch.no_grad():\n",
    "                token['labels'] = torch.tensor(1)\n",
    "                print(token)\n",
    "                token = token.to('cuda')\n",
    "                output, _ = model(**token)\n",
    "#                 features = output.last_hidden_state[:,0,:].numpy()\n",
    "                features = output\n",
    "#         L1 = len(batch_1)\n",
    "    #     print(L1)\n",
    "    #     print(features)\n",
    "#         for j in range(L1):\n",
    "                embeddings[(ii*L) + j] = features\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "963088aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = np.zeros((df_train.shape[0], 768))\n",
    "# text_embeddings = get_text_embeddings4(model, tokenizer, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cfe2c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4ebb58c3544a37a1e4f86051c8a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/watts/anaconda3/envs/shoprapids/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(df_train, tokenizer, max_length=CFG.max_length)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=CFG.batch_size, \n",
    "                                           num_workers=CFG.num_workers, \n",
    "                                           shuffle=False)\n",
    "embeddings = np.zeros((df_train.shape[0], 768))\n",
    "model.eval()\n",
    "tqdm_object = tqdm(train_loader, total=len(train_loader))\n",
    "for ii, batch in enumerate(tqdm_object):\n",
    "    batch = {k: v.to(CFG.device) for k, v in batch.items()}\n",
    "    features, _ = model(batch)\n",
    "    features = features.detach().cpu().numpy()\n",
    "#     print(len(features))\n",
    "    for j in range(len(features)):\n",
    "        embeddings[(ii*CFG.batch_size) + j] = features[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2fbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    is_all_zero = np.all(embeddings[i] == 0)\n",
    "    if is_all_zero:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "218154c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\n",
    "def get_neighbors_my(df, embeddings, KNN = 50, image = True):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    print(distances, np.max(distances), np.min(distances))\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        if image:\n",
    "            thresholds = list(np.arange(3.0, 5.0, 0.1))\n",
    "        else:\n",
    "#             thresholds = list(np.arange(0, 10, 1))\n",
    "            thresholds = list(np.arange(0.0, np.max(distances), 0.01))\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 3.6)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 20.0)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 3.6)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 20.0)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "#     gc.collect()\n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ade63be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5242712e-03 5.5242712e-03 1.5735860e+01 ... 1.7067259e+01\n",
      "  1.7068523e+01 1.7069901e+01]\n",
      " [1.6572816e-02 8.9144220e+00 8.9144220e+00 ... 1.2992506e+01\n",
      "  1.2996257e+01 1.3003769e+01]\n",
      " [1.2352647e-02 6.7761512e+00 1.1270509e+01 ... 1.4888015e+01\n",
      "  1.4893391e+01 1.4899711e+01]\n",
      " ...\n",
      " [1.5625000e-02 7.3079829e+00 7.6186833e+00 ... 1.2201635e+01\n",
      "  1.2202912e+01 1.2203353e+01]\n",
      " [1.1048542e-02 6.3377533e+00 6.4547353e+00 ... 1.1713602e+01\n",
      "  1.1713602e+01 1.1716815e+01]\n",
      " [1.2352647e-02 1.0138140e+01 1.0432563e+01 ... 1.2161659e+01\n",
      "  1.2161659e+01 1.2161659e+01]] 18.739283 0.0\n",
      "Our f1 score for threshold 0.0 is 0.0\n",
      "Our f1 score for threshold 0.1 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.2 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.30000000000000004 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.4 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.5 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.6000000000000001 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.7000000000000001 is 0.48322375878176294\n",
      "Our f1 score for threshold 0.8 is 0.4832334911418602\n",
      "Our f1 score for threshold 0.9 is 0.4832529558620548\n",
      "Our f1 score for threshold 1.0 is 0.4833249753267751\n",
      "Our f1 score for threshold 1.1 is 0.4833528747590541\n",
      "Our f1 score for threshold 1.2000000000000002 is 0.48341892290393434\n",
      "Our f1 score for threshold 1.3 is 0.4835471304105276\n",
      "Our f1 score for threshold 1.4000000000000001 is 0.48357756450038464\n",
      "Our f1 score for threshold 1.5 is 0.4837404592149021\n",
      "Our f1 score for threshold 1.6 is 0.4841077782848403\n",
      "Our f1 score for threshold 1.7000000000000002 is 0.4843881677278134\n",
      "Our f1 score for threshold 1.8 is 0.4847052529042306\n",
      "Our f1 score for threshold 1.9000000000000001 is 0.4851624852511186\n",
      "Our f1 score for threshold 2.0 is 0.48573336843215204\n",
      "Our f1 score for threshold 2.1 is 0.48624060258834734\n",
      "Our f1 score for threshold 2.2 is 0.4867972204673918\n",
      "Our f1 score for threshold 2.3000000000000003 is 0.4873383441528781\n",
      "Our f1 score for threshold 2.4000000000000004 is 0.4880551571973267\n",
      "Our f1 score for threshold 2.5 is 0.489068090074396\n",
      "Our f1 score for threshold 2.6 is 0.489924242907285\n",
      "Our f1 score for threshold 2.7 is 0.49089542309920065\n",
      "Our f1 score for threshold 2.8000000000000003 is 0.49180888441054493\n",
      "Our f1 score for threshold 2.9000000000000004 is 0.4927454812595016\n",
      "Our f1 score for threshold 3.0 is 0.49406334993947326\n",
      "Our f1 score for threshold 3.1 is 0.4950936287740181\n",
      "Our f1 score for threshold 3.2 is 0.4964663039133118\n",
      "Our f1 score for threshold 3.3000000000000003 is 0.4977055715497645\n",
      "Our f1 score for threshold 3.4000000000000004 is 0.49882819069689216\n",
      "Our f1 score for threshold 3.5 is 0.4998284022842616\n",
      "Our f1 score for threshold 3.6 is 0.5010102875176105\n",
      "Our f1 score for threshold 3.7 is 0.5025704117760205\n",
      "Our f1 score for threshold 3.8000000000000003 is 0.5036978297902555\n",
      "Our f1 score for threshold 3.9000000000000004 is 0.5050524601164917\n",
      "Our f1 score for threshold 4.0 is 0.5068063305535951\n",
      "Our f1 score for threshold 4.1000000000000005 is 0.508055370869865\n",
      "Our f1 score for threshold 4.2 is 0.5099708819542877\n",
      "Our f1 score for threshold 4.3 is 0.511310938216432\n",
      "Our f1 score for threshold 4.4 is 0.5131609407940372\n",
      "Our f1 score for threshold 4.5 is 0.5149813437796776\n",
      "Our f1 score for threshold 4.6000000000000005 is 0.5169918245218452\n",
      "Our f1 score for threshold 4.7 is 0.5190312598417426\n",
      "Our f1 score for threshold 4.800000000000001 is 0.5208640845970872\n",
      "Our f1 score for threshold 4.9 is 0.5229344827020088\n",
      "Our f1 score for threshold 5.0 is 0.5250026536574248\n",
      "Our f1 score for threshold 5.1000000000000005 is 0.527025727909905\n",
      "Our f1 score for threshold 5.2 is 0.5287984867588877\n",
      "Our f1 score for threshold 5.300000000000001 is 0.531176394554478\n",
      "Our f1 score for threshold 5.4 is 0.5332284050540175\n",
      "Our f1 score for threshold 5.5 is 0.5356967200080451\n",
      "Our f1 score for threshold 5.6000000000000005 is 0.5376625788061071\n",
      "Our f1 score for threshold 5.7 is 0.5399747404387872\n",
      "Our f1 score for threshold 5.800000000000001 is 0.5423009856148016\n",
      "Our f1 score for threshold 5.9 is 0.5449241253311347\n",
      "Our f1 score for threshold 6.0 is 0.5473427160240529\n",
      "Our f1 score for threshold 6.1000000000000005 is 0.5495359214349925\n",
      "Our f1 score for threshold 6.2 is 0.5519112198789718\n",
      "Our f1 score for threshold 6.300000000000001 is 0.5544746266298104\n",
      "Our f1 score for threshold 6.4 is 0.5569636225923573\n",
      "Our f1 score for threshold 6.5 is 0.5595293576860112\n",
      "Our f1 score for threshold 6.6000000000000005 is 0.5621650800025999\n",
      "Our f1 score for threshold 6.7 is 0.5650355570304144\n",
      "Our f1 score for threshold 6.800000000000001 is 0.5673704387712158\n",
      "Our f1 score for threshold 6.9 is 0.5699929977096839\n",
      "Our f1 score for threshold 7.0 is 0.5725054683983449\n",
      "Our f1 score for threshold 7.1000000000000005 is 0.5755344872367469\n",
      "Our f1 score for threshold 7.2 is 0.5780011269653984\n",
      "Our f1 score for threshold 7.300000000000001 is 0.5808452025178585\n",
      "Our f1 score for threshold 7.4 is 0.5831891708868046\n",
      "Our f1 score for threshold 7.5 is 0.5854904631724762\n",
      "Our f1 score for threshold 7.6000000000000005 is 0.5880704104548978\n",
      "Our f1 score for threshold 7.7 is 0.5905130507340788\n",
      "Our f1 score for threshold 7.800000000000001 is 0.5927046063941713\n",
      "Our f1 score for threshold 7.9 is 0.5944141178586465\n",
      "Our f1 score for threshold 8.0 is 0.5961764445612348\n",
      "Our f1 score for threshold 8.1 is 0.5979871340548105\n",
      "Our f1 score for threshold 8.200000000000001 is 0.5993181437214242\n",
      "Our f1 score for threshold 8.3 is 0.6008334785703097\n",
      "Our f1 score for threshold 8.4 is 0.6017309994931022\n",
      "Our f1 score for threshold 8.5 is 0.6023928205197264\n",
      "Our f1 score for threshold 8.6 is 0.6024951336357734\n",
      "Our f1 score for threshold 8.700000000000001 is 0.6025245699625643\n",
      "Our f1 score for threshold 8.8 is 0.6022852798133371\n",
      "Our f1 score for threshold 8.9 is 0.6006833677937383\n",
      "Our f1 score for threshold 9.0 is 0.5992552369048858\n",
      "Our f1 score for threshold 9.1 is 0.5972243700966701\n",
      "Our f1 score for threshold 9.200000000000001 is 0.594702535540168\n",
      "Our f1 score for threshold 9.3 is 0.5906893040468523\n",
      "Our f1 score for threshold 9.4 is 0.5864941782472072\n",
      "Our f1 score for threshold 9.5 is 0.5812467940639919\n",
      "Our f1 score for threshold 9.600000000000001 is 0.5752093194349992\n",
      "Our f1 score for threshold 9.700000000000001 is 0.5686651565286631\n",
      "Our f1 score for threshold 9.8 is 0.5606421619048607\n",
      "Our f1 score for threshold 9.9 is 0.5522537461953042\n",
      "Our f1 score for threshold 10.0 is 0.543066217811084\n",
      "Our f1 score for threshold 10.100000000000001 is 0.5331199915420383\n",
      "Our f1 score for threshold 10.200000000000001 is 0.5221932356480884\n",
      "Our f1 score for threshold 10.3 is 0.5104293422467928\n",
      "Our f1 score for threshold 10.4 is 0.49811065945657074\n",
      "Our f1 score for threshold 10.5 is 0.4854409103177538\n",
      "Our f1 score for threshold 10.600000000000001 is 0.471558199147606\n",
      "Our f1 score for threshold 10.700000000000001 is 0.4579546365927082\n",
      "Our f1 score for threshold 10.8 is 0.44321066657575364\n",
      "Our f1 score for threshold 10.9 is 0.4284337003038004\n",
      "Our f1 score for threshold 11.0 is 0.4129722736239832\n",
      "Our f1 score for threshold 11.100000000000001 is 0.3975452527666388\n",
      "Our f1 score for threshold 11.200000000000001 is 0.3820445185097543\n",
      "Our f1 score for threshold 11.3 is 0.36671813068596526\n",
      "Our f1 score for threshold 11.4 is 0.35103680766892137\n",
      "Our f1 score for threshold 11.5 is 0.33526965423661886\n",
      "Our f1 score for threshold 11.600000000000001 is 0.32011101811174963\n",
      "Our f1 score for threshold 11.700000000000001 is 0.3045094574353128\n",
      "Our f1 score for threshold 11.8 is 0.2895356269232151\n",
      "Our f1 score for threshold 11.9 is 0.2751132979157472\n",
      "Our f1 score for threshold 12.0 is 0.261010382164582\n",
      "Our f1 score for threshold 12.100000000000001 is 0.24698920705626232\n",
      "Our f1 score for threshold 12.200000000000001 is 0.2335112888508851\n",
      "Our f1 score for threshold 12.3 is 0.22120538671339127\n",
      "Our f1 score for threshold 12.4 is 0.20902494321008705\n",
      "Our f1 score for threshold 12.5 is 0.19753200055632655\n",
      "Our f1 score for threshold 12.600000000000001 is 0.18683788606886298\n",
      "Our f1 score for threshold 12.700000000000001 is 0.1765791682369473\n",
      "Our f1 score for threshold 12.8 is 0.16680274887199847\n",
      "Our f1 score for threshold 12.9 is 0.15800890739612375\n",
      "Our f1 score for threshold 13.0 is 0.14948190421693838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 13.100000000000001 is 0.14182988893306295\n",
      "Our f1 score for threshold 13.200000000000001 is 0.13494059244012965\n",
      "Our f1 score for threshold 13.3 is 0.1286039531163682\n",
      "Our f1 score for threshold 13.4 is 0.12285179177556578\n",
      "Our f1 score for threshold 13.5 is 0.11764370656248586\n",
      "Our f1 score for threshold 13.600000000000001 is 0.11295848992690073\n",
      "Our f1 score for threshold 13.700000000000001 is 0.10865455871811606\n",
      "Our f1 score for threshold 13.8 is 0.1046863853406257\n",
      "Our f1 score for threshold 13.9 is 0.1011291540642723\n",
      "Our f1 score for threshold 14.0 is 0.0981960431916164\n",
      "Our f1 score for threshold 14.100000000000001 is 0.09551283445585679\n",
      "Our f1 score for threshold 14.200000000000001 is 0.09303605358642272\n",
      "Our f1 score for threshold 14.3 is 0.09092384851334202\n",
      "Our f1 score for threshold 14.4 is 0.08912477734572902\n",
      "Our f1 score for threshold 14.5 is 0.08746853419627071\n",
      "Our f1 score for threshold 14.600000000000001 is 0.0860705968446113\n",
      "Our f1 score for threshold 14.700000000000001 is 0.08485108368125005\n",
      "Our f1 score for threshold 14.8 is 0.08369973394102276\n",
      "Our f1 score for threshold 14.9 is 0.08271805712688829\n",
      "Our f1 score for threshold 15.0 is 0.08186910143792756\n",
      "Our f1 score for threshold 15.100000000000001 is 0.08110111931382835\n",
      "Our f1 score for threshold 15.200000000000001 is 0.08048256353700295\n",
      "Our f1 score for threshold 15.3 is 0.07996127113729494\n",
      "Our f1 score for threshold 15.4 is 0.07949396457689993\n",
      "Our f1 score for threshold 15.5 is 0.07909131639600235\n",
      "Our f1 score for threshold 15.600000000000001 is 0.07873425211726531\n",
      "Our f1 score for threshold 15.700000000000001 is 0.07839619617273717\n",
      "Our f1 score for threshold 15.8 is 0.07810715867453855\n",
      "Our f1 score for threshold 15.9 is 0.07789731689317295\n",
      "Our f1 score for threshold 16.0 is 0.07769247773961077\n",
      "Our f1 score for threshold 16.1 is 0.07749041868070486\n",
      "Our f1 score for threshold 16.2 is 0.07732013550391882\n",
      "Our f1 score for threshold 16.3 is 0.07717959118923812\n",
      "Our f1 score for threshold 16.400000000000002 is 0.07704579622733312\n",
      "Our f1 score for threshold 16.5 is 0.07692414632399977\n",
      "Our f1 score for threshold 16.6 is 0.07681241899100603\n",
      "Our f1 score for threshold 16.7 is 0.07670157856358009\n",
      "Our f1 score for threshold 16.8 is 0.07663023403936764\n",
      "Our f1 score for threshold 16.900000000000002 is 0.07656428737212682\n",
      "Our f1 score for threshold 17.0 is 0.07649666739567376\n",
      "Our f1 score for threshold 17.1 is 0.0764447387718515\n",
      "Our f1 score for threshold 17.2 is 0.07639894060077772\n",
      "Our f1 score for threshold 17.3 is 0.07636761455018183\n",
      "Our f1 score for threshold 17.400000000000002 is 0.07634061363740718\n",
      "Our f1 score for threshold 17.5 is 0.0763215527639142\n",
      "Our f1 score for threshold 17.6 is 0.0763037971729537\n",
      "Our f1 score for threshold 17.7 is 0.07628319453044069\n",
      "Our f1 score for threshold 17.8 is 0.0762673076648543\n",
      "Our f1 score for threshold 17.900000000000002 is 0.07626019252302557\n",
      "Our f1 score for threshold 18.0 is 0.07625128412385065\n",
      "Our f1 score for threshold 18.1 is 0.07624784348079669\n",
      "Our f1 score for threshold 18.2 is 0.07624766778600062\n",
      "Our f1 score for threshold 18.3 is 0.07624643845140389\n",
      "Our f1 score for threshold 18.400000000000002 is 0.07624682987487283\n",
      "Our f1 score for threshold 18.5 is 0.07624587506891377\n",
      "Our f1 score for threshold 18.6 is 0.07624557410181161\n",
      "Our f1 score for threshold 18.7 is 0.07624540030966702\n",
      "Our f1 score for threshold 18.8 is 0.07624530672928145\n",
      "Our f1 score for threshold 18.900000000000002 is 0.07624530672928145\n",
      "Our best score is 0.6025245699625643 and has a threshold 8.700000000000001\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "df, image_paths = read_dataset()\n",
    "df, text_predictions = get_neighbors_my(df, embeddings, KNN = 100, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8227809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.49309734e-02, -4.93524186e-02, -3.19930837e-02,  1.39784825e-04,\n",
       "        1.64506957e-02,  3.67259011e-02,  2.18753051e-02,  8.98707099e-03,\n",
       "       -7.91010037e-02, -1.40251005e-02,  2.84586810e-02,  3.31691615e-02,\n",
       "        2.75020953e-02, -1.98368505e-02, -3.61459590e-02,  7.38642470e-04,\n",
       "       -1.21673690e-02, -3.36884931e-02, -1.29902354e-02, -1.56466290e-02,\n",
       "        7.96335116e-02,  5.22166528e-02,  2.96262726e-02, -2.75509339e-02,\n",
       "       -2.42719278e-02, -5.77889942e-02,  7.05971383e-03, -2.05163378e-02,\n",
       "       -1.15850912e-02, -5.51220477e-02,  1.72379762e-02, -2.05184016e-02,\n",
       "        2.80510038e-02, -7.42354942e-03,  2.47968752e-02,  1.67153645e-02,\n",
       "        5.07967882e-02,  4.54378873e-02,  3.52354869e-02,  1.70301385e-02,\n",
       "       -2.75660213e-02,  3.93192284e-02, -1.19878789e-02, -3.02080289e-02,\n",
       "        1.76065264e-03, -3.32429558e-02,  6.26906827e-02, -7.18075084e-03,\n",
       "       -2.46652346e-02, -7.09420117e-03, -6.80472329e-02,  1.99741162e-02,\n",
       "        1.96727235e-02, -7.66688138e-02,  2.57204417e-02,  2.49240757e-03,\n",
       "       -7.11781252e-03, -2.09529344e-02, -7.20187789e-03, -3.39794680e-02,\n",
       "        1.29137356e-02,  6.96707098e-03,  2.36302521e-02, -3.48217152e-02,\n",
       "        3.49603742e-02, -3.08650117e-02,  8.16491432e-03, -4.71974397e-03,\n",
       "        5.99370226e-02,  5.81113659e-02, -4.40883152e-02, -4.14959760e-03,\n",
       "       -3.25054303e-03, -6.56437641e-03,  2.05560308e-02,  2.77411249e-02,\n",
       "        3.22732143e-02,  1.55506912e-03,  5.75291067e-02, -4.88436408e-03,\n",
       "       -1.52403144e-02,  3.67388576e-02, -7.16318283e-03,  1.26088383e-02,\n",
       "       -1.22541264e-02, -3.96385044e-02, -5.58024794e-02,  1.45814624e-02,\n",
       "        5.49693517e-02,  4.34581116e-02,  1.91926137e-02, -4.03808169e-02,\n",
       "        2.54009627e-02, -4.17142510e-02, -5.06295066e-04, -6.25335425e-02,\n",
       "        1.57580208e-02,  3.66789550e-02, -1.54898572e-03, -6.99819205e-03,\n",
       "       -2.82413755e-02, -9.05148610e-02, -2.35751159e-02, -1.61211491e-02,\n",
       "        2.82186195e-02,  3.74514759e-02, -8.19961540e-03,  9.56643373e-02,\n",
       "        3.30412649e-02, -9.03903786e-03, -3.95455994e-02,  4.78479639e-03,\n",
       "       -5.05454540e-02, -3.31786983e-02,  3.35894898e-02,  9.35991481e-03,\n",
       "        2.16674600e-02, -3.37528177e-02,  3.78453806e-02,  2.57824250e-02,\n",
       "        2.43899729e-02,  3.11585478e-02, -4.28728908e-02, -5.46298847e-02,\n",
       "       -2.18744650e-02, -5.03511494e-03, -1.52292773e-02, -1.58264469e-02,\n",
       "        3.70703191e-02, -1.95957199e-02,  1.09936623e-02,  7.82282054e-02,\n",
       "       -9.48655047e-03,  2.34459527e-02, -8.29546526e-02, -1.03238393e-02,\n",
       "       -5.90721965e-02,  3.91667821e-02,  3.82762291e-02, -1.91767681e-02,\n",
       "        4.22388129e-02,  4.95604845e-03,  1.13115637e-02,  1.88421309e-02,\n",
       "        5.16688935e-02,  4.97554541e-02, -1.86783001e-02,  1.54034030e-02,\n",
       "       -3.75544727e-02, -9.35350880e-02, -6.62414404e-03, -3.29748057e-02,\n",
       "        5.02935937e-03,  2.08350122e-02,  1.29845273e-02, -1.37423379e-02,\n",
       "        1.94207653e-02, -3.69148068e-02, -1.66561548e-02, -3.96231115e-02,\n",
       "        1.38264438e-02, -6.06926624e-03,  4.47308719e-02,  7.20027164e-02,\n",
       "        3.26758251e-02,  5.30123301e-02,  2.85467394e-02,  2.10569408e-02,\n",
       "        3.42930444e-02,  2.18881126e-02, -4.23863791e-02, -1.24790648e-03,\n",
       "        2.06859298e-02, -6.57045469e-02, -2.39757262e-03,  2.77229007e-02,\n",
       "       -4.00120318e-02,  1.18864002e-02, -6.88264659e-03,  4.76416573e-03,\n",
       "        2.10259426e-02, -3.12933400e-02, -1.40341781e-02,  1.60080679e-02,\n",
       "       -8.02568439e-03,  2.53989343e-02, -3.27918939e-02,  2.13139504e-02,\n",
       "       -2.64886823e-02, -3.34000923e-02, -7.90701341e-03, -8.39785300e-03,\n",
       "       -1.93578843e-02, -7.82131851e-02,  1.78116877e-02, -2.17647180e-02,\n",
       "        6.07759133e-03,  7.06052557e-02,  2.02928334e-02, -1.37068760e-02,\n",
       "        9.86456964e-03, -2.82042511e-02, -2.52346955e-02,  4.29549925e-02,\n",
       "       -8.22441070e-04,  2.03598402e-02,  7.50594214e-02, -2.01288164e-02,\n",
       "        3.49596813e-02, -5.91068864e-02, -7.88815506e-03, -2.34744027e-02,\n",
       "       -8.06281939e-02,  1.83163732e-02,  2.25105416e-02, -2.22324934e-02,\n",
       "       -4.04395871e-02, -3.46601456e-02, -2.93827951e-02, -4.91740592e-02,\n",
       "       -3.45523767e-02, -1.46130053e-03, -3.35728750e-02, -3.64999734e-02,\n",
       "       -8.01682398e-02,  6.04640087e-03, -7.76389986e-02,  2.03818008e-02,\n",
       "       -4.68928032e-02, -2.96305344e-02,  1.13147506e-02, -2.16749515e-02,\n",
       "       -4.73966226e-02, -2.04142742e-02, -3.63724828e-02,  1.90605670e-02,\n",
       "       -1.14130536e-02, -2.30429769e-02, -2.31163148e-02,  2.69622845e-03,\n",
       "        9.44015756e-03,  1.00485487e-02,  4.69452888e-02,  2.83872187e-02,\n",
       "        2.33328417e-02,  2.04612426e-02, -7.53155537e-03, -3.17673534e-02,\n",
       "        6.60379529e-02,  4.73243520e-02,  3.12483739e-02,  4.90729883e-02,\n",
       "        1.28642432e-02,  1.84606239e-02,  1.59137342e-02,  1.69364680e-02,\n",
       "       -6.32931711e-04, -3.66204754e-02,  3.55243646e-02,  3.11569404e-03,\n",
       "       -4.56479937e-02,  6.26314953e-02, -1.76851414e-02, -1.32038463e-02,\n",
       "        1.57575253e-02, -3.46298106e-02, -3.05506084e-02,  2.87087038e-02,\n",
       "        9.84593667e-03,  4.77019474e-02, -1.25081409e-02, -2.27971952e-02,\n",
       "       -4.45045531e-03,  4.26349044e-02,  3.92706804e-02, -2.01078504e-02,\n",
       "        2.61693392e-02,  1.44559480e-02,  7.37748742e-02,  1.50776114e-02,\n",
       "       -1.61752552e-02,  5.49660176e-02,  3.44892219e-02, -4.63311225e-02,\n",
       "        1.11880638e-02, -2.15850621e-02,  2.17880774e-02,  7.20932847e-03,\n",
       "       -2.83772796e-02,  4.24059555e-02, -2.86069438e-02,  1.26822740e-02,\n",
       "        2.67255958e-02, -2.02097539e-02,  4.49370593e-03,  1.80928707e-02,\n",
       "       -1.72144771e-02,  5.83474375e-02,  5.44643849e-02, -7.45466053e-02,\n",
       "       -3.96652408e-02, -2.72828806e-02,  1.06366770e-02,  1.51894316e-02,\n",
       "        6.71096984e-03,  5.94256260e-02, -4.21727039e-02,  2.19674152e-03,\n",
       "        5.77213168e-02,  1.58539624e-04, -5.12514031e-03,  2.42265360e-03,\n",
       "       -9.41651408e-03,  3.54147106e-02,  2.36634798e-02,  2.22603939e-02,\n",
       "       -6.32416680e-02, -6.63185567e-02,  4.26084772e-02, -2.04488635e-02,\n",
       "       -7.17599131e-03,  4.00913805e-02, -2.88554765e-02,  1.71898473e-02,\n",
       "       -3.66852013e-03, -1.94601491e-02, -3.77698317e-02, -3.49839893e-03,\n",
       "       -1.58047471e-02,  1.88919585e-02, -7.55586922e-02, -6.00650385e-02,\n",
       "        4.42244373e-02, -1.59625672e-02, -3.70621867e-02, -7.73711577e-02,\n",
       "        3.47126536e-02,  3.76683436e-02,  4.32127304e-02, -2.15230137e-02,\n",
       "       -3.97469550e-02, -5.56107089e-02,  2.49347067e-03, -1.43491542e-02,\n",
       "       -1.59456823e-02, -1.22033125e-02,  1.53132556e-02,  4.42150980e-02,\n",
       "       -3.05539686e-02, -3.70962545e-02,  3.79599743e-02,  6.61807135e-02,\n",
       "       -2.26799659e-02,  4.67417203e-02, -6.19839244e-02, -3.10589024e-03,\n",
       "       -6.08014427e-02,  2.42524669e-02,  1.30112357e-02,  6.21803030e-02,\n",
       "        2.06012838e-02, -4.34887074e-02, -4.33277572e-03, -2.24316493e-02,\n",
       "       -1.12655375e-03,  3.89762148e-02, -9.87410359e-03,  1.78975537e-02,\n",
       "       -2.16005594e-02,  3.81570458e-02,  5.52917831e-03, -1.04557313e-02,\n",
       "        2.83225216e-02, -4.39674268e-03, -6.77265925e-03,  7.06046913e-03,\n",
       "        2.02014185e-02, -1.40581708e-02,  2.86315195e-02, -5.85763678e-02,\n",
       "       -8.06953534e-02,  5.38472040e-03,  6.76262826e-02,  9.91347060e-02,\n",
       "        2.50646584e-02,  5.66603616e-02,  3.17354989e-03,  1.15161657e-01,\n",
       "       -4.30402383e-02,  2.79066134e-02, -2.10689828e-02,  2.72721052e-02,\n",
       "       -1.03731761e-02,  1.91510469e-02, -3.84496488e-02,  2.00991444e-02,\n",
       "       -3.12747099e-02, -3.15108113e-02, -7.18798488e-02,  1.27252806e-02,\n",
       "        1.69698976e-03,  2.95413076e-03, -1.91447698e-02, -8.47848319e-03,\n",
       "        5.13549261e-02,  1.51531724e-02,  5.19484747e-04,  2.63231620e-02,\n",
       "        3.45257297e-02,  2.02478226e-02, -2.53113825e-02, -5.31750470e-02,\n",
       "       -6.12985622e-03, -2.21462119e-02,  2.23750267e-02,  3.00237089e-02,\n",
       "       -5.11100963e-02, -3.18761356e-02,  7.06667663e-04,  7.87276309e-03,\n",
       "        4.73699197e-02, -2.58022477e-03, -3.94534646e-03, -7.20903501e-02,\n",
       "        2.22319420e-02,  3.32508795e-02,  3.76564786e-02,  8.86137597e-03,\n",
       "       -1.26794074e-02, -7.49065680e-03,  1.47905350e-02, -2.40790118e-02,\n",
       "       -8.45442563e-02,  3.22325602e-02, -2.91527174e-02, -3.20162391e-03,\n",
       "       -4.05185297e-02,  9.58762504e-03, -4.77422103e-02,  6.61576092e-02,\n",
       "       -6.80638244e-03,  1.52283460e-02,  2.70179920e-02, -6.60425238e-03,\n",
       "        1.36427581e-02, -4.72344682e-02,  1.40714757e-02, -1.56589260e-03,\n",
       "        3.42953540e-02, -1.19338627e-03,  1.28240222e-02,  4.90944572e-02,\n",
       "       -1.34738050e-02, -5.58406822e-02,  2.13774629e-02,  5.64517034e-03,\n",
       "       -3.01901228e-03,  2.76662968e-02, -3.06061190e-02, -5.23783974e-02,\n",
       "        3.41205276e-03,  2.18651164e-03,  1.92126483e-02, -3.01243551e-02,\n",
       "        7.84260258e-02,  4.00146432e-02, -2.71135531e-02, -1.02530979e-02,\n",
       "        1.37501513e-03,  5.02097607e-02,  4.82514203e-02, -3.07465922e-02,\n",
       "       -5.17950803e-02, -1.36925047e-02, -7.56583288e-02,  6.08906662e-03,\n",
       "        6.08810298e-02,  7.11677000e-02, -1.10411774e-02,  1.13263978e-02,\n",
       "       -6.02431013e-04,  6.85696397e-03,  1.71049517e-02, -8.65577196e-04,\n",
       "       -2.54568155e-03, -4.25085388e-02,  1.81581080e-02,  7.24135339e-02,\n",
       "        2.17281878e-02,  4.18866649e-02,  5.02237417e-02, -2.65065096e-02,\n",
       "       -1.22168558e-02,  4.07790253e-03,  4.22118939e-02, -6.16823584e-02,\n",
       "        6.81349710e-02,  4.69338670e-02,  1.24607282e-02,  3.37406551e-03,\n",
       "       -4.37130732e-03,  1.36393365e-02,  2.71789897e-02,  5.26073650e-02,\n",
       "       -4.13379483e-02, -3.39687616e-02,  2.48984303e-02,  2.23573018e-03,\n",
       "        3.63152362e-02,  1.24275377e-02, -3.33944336e-02, -2.71315761e-02,\n",
       "        1.87264697e-03, -5.39243110e-02, -9.24475398e-03,  7.89166093e-02,\n",
       "       -5.41200303e-02,  2.48118378e-02, -1.87917780e-02,  5.66420443e-02,\n",
       "        3.17394943e-03,  6.17954396e-02,  1.10998368e-02,  6.00115284e-02,\n",
       "        2.91094314e-02, -7.40637444e-03, -2.05120146e-02, -2.43291929e-02,\n",
       "        1.40153673e-02,  2.63307765e-02,  3.47901024e-02, -2.39494629e-02,\n",
       "        1.06953857e-02,  7.00016096e-02,  5.61814196e-02,  9.19811353e-02,\n",
       "       -1.09153446e-02,  2.32606917e-03, -2.77430266e-02, -2.60046329e-02,\n",
       "        8.96997675e-02, -5.01138009e-02,  1.79540254e-02,  4.49317954e-02,\n",
       "       -2.05278285e-02, -4.03984860e-02, -4.58283685e-02,  4.91108820e-02,\n",
       "       -6.62890226e-02,  4.44268622e-02, -9.24535748e-03, -6.61388263e-02,\n",
       "       -2.14774404e-02,  1.69517174e-02,  4.65707816e-02,  9.12829782e-05,\n",
       "       -1.33762956e-02, -5.46434000e-02, -1.98484845e-02, -3.27168442e-02,\n",
       "        1.40353786e-02,  4.58660908e-03,  1.50226913e-02,  7.17610270e-02,\n",
       "       -2.48048101e-02, -3.80987488e-02, -3.15889604e-02, -5.79388142e-02,\n",
       "        4.13515344e-02, -4.04647850e-02, -3.62731218e-02,  2.85563637e-02,\n",
       "       -1.38026848e-02,  5.06450832e-02,  4.55081724e-02, -2.61877701e-02,\n",
       "       -3.88772227e-02, -2.88746804e-02,  6.61038607e-02, -4.12060926e-03,\n",
       "        6.03823271e-03,  3.65816541e-02, -2.50312872e-02, -1.33462623e-02,\n",
       "        5.39035872e-02, -3.73085029e-02, -4.18713503e-02, -2.63168551e-02,\n",
       "       -3.52823101e-02,  4.73851757e-03,  3.78231741e-02, -5.00151608e-03,\n",
       "        3.17846052e-02, -2.87199952e-02,  5.34876920e-02,  6.75912872e-02,\n",
       "        3.10967024e-02, -2.00401135e-02, -4.47447188e-02, -6.40508831e-02,\n",
       "       -1.58337671e-02, -1.74268410e-02,  4.77081805e-04, -3.81603278e-02,\n",
       "       -3.84270996e-02, -3.60252410e-02,  3.98605280e-02, -3.45323645e-02,\n",
       "       -6.55116662e-02, -2.64634062e-02,  1.19560305e-02,  3.71221267e-02,\n",
       "       -4.39352402e-03, -5.99573227e-03, -6.02269545e-02,  5.72425835e-02,\n",
       "        6.30728947e-03,  9.51904152e-03,  2.29047369e-02,  1.30417841e-02,\n",
       "       -3.74172926e-02, -1.41081270e-02, -7.70707102e-03,  7.77434278e-03,\n",
       "        3.73242386e-02,  1.29889790e-02, -3.33409803e-03,  5.97391501e-02,\n",
       "       -2.95583680e-02, -2.57520676e-02,  3.09134647e-02, -1.12949982e-02,\n",
       "       -5.15475832e-02,  2.51961630e-02,  4.47282977e-02, -1.58682838e-02,\n",
       "       -5.45313656e-02, -8.17245524e-03,  3.64345610e-02, -2.95768026e-03,\n",
       "       -2.49909516e-02,  8.43433477e-03, -2.31905617e-02,  2.08540130e-02,\n",
       "        1.67409088e-02,  3.51629872e-03,  1.82944108e-02,  3.15453857e-02,\n",
       "       -3.66693474e-02, -2.88983565e-02, -3.71143930e-02,  9.85127315e-03,\n",
       "       -4.50767018e-02,  3.13799381e-02,  2.38548387e-02, -1.57513015e-03,\n",
       "       -4.47083078e-02,  1.68358628e-02,  3.89551260e-02,  6.35864437e-02,\n",
       "       -2.89824102e-02,  1.74612552e-02,  6.29974343e-03,  2.86490694e-02,\n",
       "        3.15442272e-02,  2.13746657e-03, -5.25882468e-03, -6.32249238e-03,\n",
       "        2.10631359e-02,  2.71650380e-03,  4.55484055e-02,  3.25173102e-02,\n",
       "        1.02174673e-02, -2.01561451e-02,  3.56316343e-02,  3.08455210e-02,\n",
       "       -3.72034945e-02,  2.22475835e-04, -5.63894249e-02,  9.90391895e-03,\n",
       "        2.66047642e-02, -5.16920649e-02,  1.54074142e-02,  5.87794669e-02,\n",
       "        3.30568850e-02, -2.15177443e-02,  4.79079671e-02, -8.74619093e-03,\n",
       "       -3.32887433e-02, -1.83118898e-02, -8.78075957e-02, -1.83905885e-02,\n",
       "       -1.13441221e-01, -6.28636330e-02,  1.14527307e-02,  1.72489621e-02,\n",
       "       -2.00058669e-02, -2.01781299e-02, -4.62820195e-02, -3.69199477e-02,\n",
       "       -2.64870599e-02, -1.21306162e-02, -2.12210529e-02, -7.61437267e-02,\n",
       "       -3.62369269e-02, -2.13148445e-02,  9.86777619e-03, -2.36313716e-02,\n",
       "        3.09227835e-02, -5.95310144e-02, -3.47491391e-02, -2.40692254e-02,\n",
       "       -6.67981654e-02,  8.18054564e-03, -6.71853572e-02, -3.12619656e-02,\n",
       "       -2.46455446e-02, -1.79849993e-02, -7.15466077e-03, -1.28644230e-02,\n",
       "       -1.09482810e-01, -3.78054902e-02, -3.29364762e-02, -2.13977247e-02,\n",
       "       -2.45407559e-02,  8.86575207e-02, -2.69483775e-02, -2.29186341e-02,\n",
       "        1.95811614e-02,  1.76959159e-03,  5.28549962e-02, -2.53263377e-02,\n",
       "       -4.55511361e-02, -4.45367284e-02,  1.89861916e-02,  2.50825919e-02,\n",
       "       -1.41588263e-02, -3.50810289e-02,  6.48372108e-03,  2.24544667e-02,\n",
       "        3.16592269e-02,  1.01217832e-02,  1.05244489e-02,  1.26304403e-02,\n",
       "        8.38679820e-03,  6.50742128e-02,  3.73410471e-02, -6.76846281e-02,\n",
       "        3.65516841e-02,  1.77873578e-02,  2.51837511e-04, -4.13693022e-03,\n",
       "        1.70872603e-02, -4.31517065e-02, -7.10357679e-03, -2.90838629e-02,\n",
       "        6.25978550e-03,  1.22988671e-02,  4.53413203e-02,  3.68173309e-02,\n",
       "       -1.34796128e-02, -1.55963586e-04, -1.48851974e-02,  5.85673153e-02,\n",
       "        2.23803874e-02,  2.25869776e-03, -5.02994470e-02,  1.03602499e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 9.8271418e-01 ... 1.2887474e+00\n",
      "  1.2887806e+00 1.2888637e+00]\n",
      " [0.0000000e+00 4.0418193e-01 1.0928062e+00 ... 1.2726147e+00\n",
      "  1.2726355e+00 1.2729268e+00]\n",
      " [8.4572798e-04 5.7721794e-01 1.2360779e+00 ... 1.2869883e+00\n",
      "  1.2873298e+00 1.2874553e+00]\n",
      " ...\n",
      " [0.0000000e+00 3.9723623e-01 4.4565943e-01 ... 1.2625575e+00\n",
      "  1.2630612e+00 1.2632903e+00]\n",
      " [3.4526695e-04 3.1192595e-01 6.5062594e-01 ... 1.2805060e+00\n",
      "  1.2811129e+00 1.2813334e+00]\n",
      " [0.0000000e+00 9.5275950e-01 1.0726937e+00 ... 1.2783222e+00\n",
      "  1.2783383e+00 1.2792993e+00]] 1.3041706 0.0\n",
      "Our f1 score for threshold 0.0 is 0.0\n",
      "Our f1 score for threshold 0.01 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.02 is 0.48321472159024387\n",
      "Our f1 score for threshold 0.03 is 0.4832195685363794\n",
      "Our f1 score for threshold 0.04 is 0.4832195685363794\n",
      "Our f1 score for threshold 0.05 is 0.48322194985853084\n",
      "Our f1 score for threshold 0.06 is 0.48327360440335665\n",
      "Our f1 score for threshold 0.07 is 0.4834080782447073\n",
      "Our f1 score for threshold 0.08 is 0.4834820368330882\n",
      "Our f1 score for threshold 0.09 is 0.4837863208338938\n",
      "Our f1 score for threshold 0.1 is 0.4840018363090191\n",
      "Our f1 score for threshold 0.11 is 0.4843944227532111\n",
      "Our f1 score for threshold 0.12 is 0.48482896679696996\n",
      "Our f1 score for threshold 0.13 is 0.485703846344157\n",
      "Our f1 score for threshold 0.14 is 0.4868269934205292\n",
      "Our f1 score for threshold 0.15 is 0.48808147894330456\n",
      "Our f1 score for threshold 0.16 is 0.4897382631990861\n",
      "Our f1 score for threshold 0.17 is 0.4914177518572088\n",
      "Our f1 score for threshold 0.18 is 0.4933615703174828\n",
      "Our f1 score for threshold 0.19 is 0.4956337012309302\n",
      "Our f1 score for threshold 0.2 is 0.4980551389645536\n",
      "Our f1 score for threshold 0.21 is 0.5007218100699443\n",
      "Our f1 score for threshold 0.22 is 0.5037380477911755\n",
      "Our f1 score for threshold 0.23 is 0.5067219375542596\n",
      "Our f1 score for threshold 0.24 is 0.5104389481988284\n",
      "Our f1 score for threshold 0.25 is 0.5149556002683984\n",
      "Our f1 score for threshold 0.26 is 0.519456936809873\n",
      "Our f1 score for threshold 0.27 is 0.5245051685541213\n",
      "Our f1 score for threshold 0.28 is 0.5296593661256822\n",
      "Our f1 score for threshold 0.29 is 0.5351885681405596\n",
      "Our f1 score for threshold 0.3 is 0.5417408461901692\n",
      "Our f1 score for threshold 0.31 is 0.5490514620312485\n",
      "Our f1 score for threshold 0.32 is 0.5566657052013101\n",
      "Our f1 score for threshold 0.33 is 0.5652534991228353\n",
      "Our f1 score for threshold 0.34 is 0.5736617922164001\n",
      "Our f1 score for threshold 0.35000000000000003 is 0.5828446869213454\n",
      "Our f1 score for threshold 0.36 is 0.5921739318443598\n",
      "Our f1 score for threshold 0.37 is 0.6027708154316723\n",
      "Our f1 score for threshold 0.38 is 0.6138053877333742\n",
      "Our f1 score for threshold 0.39 is 0.6256543192281838\n",
      "Our f1 score for threshold 0.4 is 0.6373718398810355\n",
      "Our f1 score for threshold 0.41000000000000003 is 0.6493830558286317\n",
      "Our f1 score for threshold 0.42 is 0.6609005116839376\n",
      "Our f1 score for threshold 0.43 is 0.6728207290290914\n",
      "Our f1 score for threshold 0.44 is 0.6845876522086529\n",
      "Our f1 score for threshold 0.45 is 0.6955233925050183\n",
      "Our f1 score for threshold 0.46 is 0.7057247882194927\n",
      "Our f1 score for threshold 0.47000000000000003 is 0.7159727707288169\n",
      "Our f1 score for threshold 0.48 is 0.7252303788832217\n",
      "Our f1 score for threshold 0.49 is 0.7337819959327407\n",
      "Our f1 score for threshold 0.5 is 0.7427687856758594\n",
      "Our f1 score for threshold 0.51 is 0.7513318089693761\n",
      "Our f1 score for threshold 0.52 is 0.7589089961817276\n",
      "Our f1 score for threshold 0.53 is 0.7660879986900998\n",
      "Our f1 score for threshold 0.54 is 0.772242391190279\n",
      "Our f1 score for threshold 0.55 is 0.7782957352361802\n",
      "Our f1 score for threshold 0.56 is 0.7838675188082479\n",
      "Our f1 score for threshold 0.5700000000000001 is 0.7894247684686293\n",
      "Our f1 score for threshold 0.58 is 0.7945446004476301\n",
      "Our f1 score for threshold 0.59 is 0.7997330188889287\n",
      "Our f1 score for threshold 0.6 is 0.803834857966984\n",
      "Our f1 score for threshold 0.61 is 0.8078822942722494\n",
      "Our f1 score for threshold 0.62 is 0.8112746631779248\n",
      "Our f1 score for threshold 0.63 is 0.8144217995916123\n",
      "Our f1 score for threshold 0.64 is 0.8177167797516033\n",
      "Our f1 score for threshold 0.65 is 0.8202315138873911\n",
      "Our f1 score for threshold 0.66 is 0.822750237032486\n",
      "Our f1 score for threshold 0.67 is 0.8253392635357952\n",
      "Our f1 score for threshold 0.68 is 0.8274614872876837\n",
      "Our f1 score for threshold 0.6900000000000001 is 0.8295837858924048\n",
      "Our f1 score for threshold 0.7000000000000001 is 0.8314868793935614\n",
      "Our f1 score for threshold 0.71 is 0.8337355471417494\n",
      "Our f1 score for threshold 0.72 is 0.8355216124135468\n",
      "Our f1 score for threshold 0.73 is 0.8375225435883021\n",
      "Our f1 score for threshold 0.74 is 0.8389358476560743\n",
      "Our f1 score for threshold 0.75 is 0.8407575979160116\n",
      "Our f1 score for threshold 0.76 is 0.8426707394053418\n",
      "Our f1 score for threshold 0.77 is 0.8446354030778698\n",
      "Our f1 score for threshold 0.78 is 0.8463384228397695\n",
      "Our f1 score for threshold 0.79 is 0.8479959618589219\n",
      "Our f1 score for threshold 0.8 is 0.8497620270300261\n",
      "Our f1 score for threshold 0.81 is 0.8514220111966901\n",
      "Our f1 score for threshold 0.8200000000000001 is 0.8530449677146809\n",
      "Our f1 score for threshold 0.8300000000000001 is 0.8546895408733657\n",
      "Our f1 score for threshold 0.84 is 0.856216056852815\n",
      "Our f1 score for threshold 0.85 is 0.8574339506209652\n",
      "Our f1 score for threshold 0.86 is 0.8585866059956117\n",
      "Our f1 score for threshold 0.87 is 0.8597982331431908\n",
      "Our f1 score for threshold 0.88 is 0.8611077245195459\n",
      "Our f1 score for threshold 0.89 is 0.8621566719836721\n",
      "Our f1 score for threshold 0.9 is 0.862798285424022\n",
      "Our f1 score for threshold 0.91 is 0.863511699532865\n",
      "Our f1 score for threshold 0.92 is 0.8641835474411624\n",
      "Our f1 score for threshold 0.93 is 0.8647216275390863\n",
      "Our f1 score for threshold 0.9400000000000001 is 0.8650362688204538\n",
      "Our f1 score for threshold 0.9500000000000001 is 0.8651692331542492\n",
      "Our f1 score for threshold 0.96 is 0.8651502359237838\n",
      "Our f1 score for threshold 0.97 is 0.8652546644905392\n",
      "Our f1 score for threshold 0.98 is 0.8650965781474983\n",
      "Our f1 score for threshold 0.99 is 0.8641382604056549\n",
      "Our f1 score for threshold 1.0 is 0.8630206162828492\n",
      "Our f1 score for threshold 1.01 is 0.8615169568423969\n",
      "Our f1 score for threshold 1.02 is 0.859591954141358\n",
      "Our f1 score for threshold 1.03 is 0.8576776112188018\n",
      "Our f1 score for threshold 1.04 is 0.855164809303244\n",
      "Our f1 score for threshold 1.05 is 0.8524407605425092\n",
      "Our f1 score for threshold 1.06 is 0.8488791441105117\n",
      "Our f1 score for threshold 1.07 is 0.8446829420041956\n",
      "Our f1 score for threshold 1.08 is 0.8394506387125057\n",
      "Our f1 score for threshold 1.09 is 0.833637519179929\n",
      "Our f1 score for threshold 1.1 is 0.8267112956888335\n",
      "Our f1 score for threshold 1.11 is 0.8180283964017651\n",
      "Our f1 score for threshold 1.12 is 0.8070482594897941\n",
      "Our f1 score for threshold 1.1300000000000001 is 0.7932397899171276\n",
      "Our f1 score for threshold 1.1400000000000001 is 0.7761144680386104\n",
      "Our f1 score for threshold 1.1500000000000001 is 0.7538502904040594\n",
      "Our f1 score for threshold 1.16 is 0.7252666140419868\n",
      "Our f1 score for threshold 1.17 is 0.6894695065546148\n",
      "Our f1 score for threshold 1.18 is 0.6459128675941517\n",
      "Our f1 score for threshold 1.19 is 0.593873381876261\n",
      "Our f1 score for threshold 1.2 is 0.5344497122037031\n",
      "Our f1 score for threshold 1.21 is 0.46879653886244216\n",
      "Our f1 score for threshold 1.22 is 0.4000202289169722\n",
      "Our f1 score for threshold 1.23 is 0.33044614846554515\n",
      "Our f1 score for threshold 1.24 is 0.26359880507341393\n",
      "Our f1 score for threshold 1.25 is 0.20422273718349085\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "df, image_paths = read_dataset()\n",
    "df, text_predictions = get_neighbors_my(df, embeddings, KNN = 100, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7bdb05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 1.2196290e+00 ... 1.2886680e+00\n",
      "  1.2887913e+00 1.2888253e+00]\n",
      " [0.0000000e+00 3.7186134e-01 1.1943014e+00 ... 1.2698030e+00\n",
      "  1.2699094e+00 1.2704245e+00]\n",
      " [0.0000000e+00 2.5319335e-01 1.1701527e+00 ... 1.2820879e+00\n",
      "  1.2821680e+00 1.2827332e+00]\n",
      " ...\n",
      " [0.0000000e+00 2.8946760e-01 3.0613992e-01 ... 1.2827525e+00\n",
      "  1.2828901e+00 1.2830571e+00]\n",
      " [0.0000000e+00 2.6964420e-01 3.3551425e-01 ... 1.2734960e+00\n",
      "  1.2736859e+00 1.2739505e+00]\n",
      " [9.1349054e-04 4.0595689e-01 1.1516600e+00 ... 1.2790155e+00\n",
      "  1.2790155e+00 1.2790155e+00]] 1.301319 0.0\n",
      "Our f1 score for threshold 0.0 is 0.0\n",
      "Our f1 score for threshold 0.01 is 0.4837554183391004\n",
      "Our f1 score for threshold 0.02 is 0.4837554183391004\n",
      "Our f1 score for threshold 0.03 is 0.4837602652852359\n",
      "Our f1 score for threshold 0.04 is 0.4837968126794476\n",
      "Our f1 score for threshold 0.05 is 0.48383005318732947\n",
      "Our f1 score for threshold 0.06 is 0.4839107747581283\n",
      "Our f1 score for threshold 0.07 is 0.4840096193970045\n",
      "Our f1 score for threshold 0.08 is 0.48440742070807263\n",
      "Our f1 score for threshold 0.09 is 0.48495807044083167\n",
      "Our f1 score for threshold 0.1 is 0.4858080675486218\n",
      "Our f1 score for threshold 0.11 is 0.4868119783393064\n",
      "Our f1 score for threshold 0.12 is 0.4882904990147795\n",
      "Our f1 score for threshold 0.13 is 0.48997056793591964\n",
      "Our f1 score for threshold 0.14 is 0.4919337152071928\n",
      "Our f1 score for threshold 0.15 is 0.4943985928357518\n",
      "Our f1 score for threshold 0.16 is 0.49738571428719175\n",
      "Our f1 score for threshold 0.17 is 0.501335494229863\n",
      "Our f1 score for threshold 0.18 is 0.5057417071504529\n",
      "Our f1 score for threshold 0.19 is 0.5105814726556214\n",
      "Our f1 score for threshold 0.2 is 0.5152091530275992\n",
      "Our f1 score for threshold 0.21 is 0.521290222148124\n",
      "Our f1 score for threshold 0.22 is 0.5285963283268298\n",
      "Our f1 score for threshold 0.23 is 0.5360704968120983\n",
      "Our f1 score for threshold 0.24 is 0.5450481694614508\n",
      "Our f1 score for threshold 0.25 is 0.5547567360446778\n",
      "Our f1 score for threshold 0.26 is 0.5655831054521078\n",
      "Our f1 score for threshold 0.27 is 0.5772417398729427\n",
      "Our f1 score for threshold 0.28 is 0.5904600952149399\n",
      "Our f1 score for threshold 0.29 is 0.604606123798513\n",
      "Our f1 score for threshold 0.3 is 0.6199438290052115\n",
      "Our f1 score for threshold 0.31 is 0.6364734498304845\n",
      "Our f1 score for threshold 0.32 is 0.6550206565453106\n",
      "Our f1 score for threshold 0.33 is 0.6739505644323607\n",
      "Our f1 score for threshold 0.34 is 0.6934284533889746\n",
      "Our f1 score for threshold 0.35000000000000003 is 0.7142176033971276\n",
      "Our f1 score for threshold 0.36 is 0.7354032925162173\n",
      "Our f1 score for threshold 0.37 is 0.7563339187987678\n",
      "Our f1 score for threshold 0.38 is 0.7775194829214842\n",
      "Our f1 score for threshold 0.39 is 0.797701073040699\n",
      "Our f1 score for threshold 0.4 is 0.8179659697196318\n",
      "Our f1 score for threshold 0.41000000000000003 is 0.8374433710621134\n",
      "Our f1 score for threshold 0.42 is 0.8542017234582949\n",
      "Our f1 score for threshold 0.43 is 0.871030333269688\n",
      "Our f1 score for threshold 0.44 is 0.8855698221793359\n",
      "Our f1 score for threshold 0.45 is 0.8990170087661054\n",
      "Our f1 score for threshold 0.46 is 0.9111784510262823\n",
      "Our f1 score for threshold 0.47000000000000003 is 0.9224103933647411\n",
      "Our f1 score for threshold 0.48 is 0.9332336835224093\n",
      "Our f1 score for threshold 0.49 is 0.9427790520363698\n",
      "Our f1 score for threshold 0.5 is 0.9517510134102241\n",
      "Our f1 score for threshold 0.51 is 0.9591348980052968\n",
      "Our f1 score for threshold 0.52 is 0.9656847526246501\n",
      "Our f1 score for threshold 0.53 is 0.9714507912058726\n",
      "Our f1 score for threshold 0.54 is 0.9762664346159253\n",
      "Our f1 score for threshold 0.55 is 0.9804961128539375\n",
      "Our f1 score for threshold 0.56 is 0.983795159111218\n",
      "Our f1 score for threshold 0.5700000000000001 is 0.9861397268380536\n",
      "Our f1 score for threshold 0.58 is 0.988116019411133\n",
      "Our f1 score for threshold 0.59 is 0.9897619145276538\n",
      "Our f1 score for threshold 0.6 is 0.9909665750114817\n",
      "Our f1 score for threshold 0.61 is 0.9920342430743005\n",
      "Our f1 score for threshold 0.62 is 0.9926973166884219\n",
      "Our f1 score for threshold 0.63 is 0.9930545648042528\n",
      "Our f1 score for threshold 0.64 is 0.9933989039135555\n",
      "Our f1 score for threshold 0.65 is 0.993609988595297\n",
      "Our f1 score for threshold 0.66 is 0.9937562155513113\n",
      "Our f1 score for threshold 0.67 is 0.9937972385688595\n",
      "Our f1 score for threshold 0.68 is 0.993875097449638\n",
      "Our f1 score for threshold 0.6900000000000001 is 0.9939185187485338\n",
      "Our f1 score for threshold 0.7000000000000001 is 0.9939379834687285\n",
      "Our f1 score for threshold 0.71 is 0.9939379834687285\n",
      "Our f1 score for threshold 0.72 is 0.9939548065483254\n",
      "Our f1 score for threshold 0.73 is 0.9939500119482139\n",
      "Our f1 score for threshold 0.74 is 0.9939655163140831\n",
      "Our f1 score for threshold 0.75 is 0.9939672482399027\n",
      "Our f1 score for threshold 0.76 is 0.9939808262033734\n",
      "Our f1 score for threshold 0.77 is 0.9939817803177278\n",
      "Our f1 score for threshold 0.78 is 0.9939718489248915\n",
      "Our f1 score for threshold 0.79 is 0.9939657520056727\n",
      "Our f1 score for threshold 0.8 is 0.9939687025751326\n",
      "Our f1 score for threshold 0.81 is 0.9939562198569498\n",
      "Our f1 score for threshold 0.8200000000000001 is 0.9939629461821944\n",
      "Our f1 score for threshold 0.8300000000000001 is 0.9939706360890027\n",
      "Our f1 score for threshold 0.84 is 0.9939709964747646\n",
      "Our f1 score for threshold 0.85 is 0.9939634462510517\n",
      "Our f1 score for threshold 0.86 is 0.9939735330781235\n",
      "Our f1 score for threshold 0.87 is 0.9939687718330374\n",
      "Our f1 score for threshold 0.88 is 0.9939751700380971\n",
      "Our f1 score for threshold 0.89 is 0.9939534135479149\n",
      "Our f1 score for threshold 0.9 is 0.9939580528610727\n",
      "Our f1 score for threshold 0.91 is 0.9939674352082399\n",
      "Our f1 score for threshold 0.92 is 0.9939491283674982\n",
      "Our f1 score for threshold 0.93 is 0.9939554572697431\n",
      "Our f1 score for threshold 0.9400000000000001 is 0.9939732457248887\n",
      "Our f1 score for threshold 0.9500000000000001 is 0.9939782614813706\n",
      "Our f1 score for threshold 0.96 is 0.9940226094633012\n",
      "Our f1 score for threshold 0.97 is 0.9940536240679142\n",
      "Our f1 score for threshold 0.98 is 0.9940463178585529\n",
      "Our f1 score for threshold 0.99 is 0.9940633342420524\n",
      "Our f1 score for threshold 1.0 is 0.9940821538426002\n",
      "Our f1 score for threshold 1.01 is 0.9940867553063909\n",
      "Our f1 score for threshold 1.02 is 0.9941121934329051\n",
      "Our f1 score for threshold 1.03 is 0.9941285485465544\n",
      "Our f1 score for threshold 1.04 is 0.9940614329058266\n",
      "Our f1 score for threshold 1.05 is 0.9940644025527496\n",
      "Our f1 score for threshold 1.06 is 0.9939662071817335\n",
      "Our f1 score for threshold 1.07 is 0.9938309178540059\n",
      "Our f1 score for threshold 1.08 is 0.9936205411748045\n",
      "Our f1 score for threshold 1.09 is 0.9933487192598133\n",
      "Our f1 score for threshold 1.1 is 0.9928073228273882\n",
      "Our f1 score for threshold 1.11 is 0.9918251324112263\n",
      "Our f1 score for threshold 1.12 is 0.9895971864349341\n",
      "Our f1 score for threshold 1.1300000000000001 is 0.9856003695407997\n",
      "Our f1 score for threshold 1.1400000000000001 is 0.9788353649897718\n",
      "Our f1 score for threshold 1.1500000000000001 is 0.9663232651913974\n",
      "Our f1 score for threshold 1.16 is 0.9451224266038826\n",
      "Our f1 score for threshold 1.17 is 0.9088952506478248\n",
      "Our f1 score for threshold 1.18 is 0.8565182442444134\n",
      "Our f1 score for threshold 1.19 is 0.784516786323217\n",
      "Our f1 score for threshold 1.2 is 0.6940537425587716\n",
      "Our f1 score for threshold 1.21 is 0.5900537803203038\n",
      "Our f1 score for threshold 1.22 is 0.47928844264320825\n",
      "Our f1 score for threshold 1.23 is 0.37400276404420374\n",
      "Our f1 score for threshold 1.24 is 0.28074694202504263\n",
      "Our f1 score for threshold 1.25 is 0.20566819640127687\n",
      "Our f1 score for threshold 1.26 is 0.15144157868974212\n",
      "Our f1 score for threshold 1.27 is 0.11876983251505185\n",
      "Our f1 score for threshold 1.28 is 0.10533233823162741\n",
      "Our f1 score for threshold 1.29 is 0.10286675670333595\n",
      "Our f1 score for threshold 1.3 is 0.10275558913039991\n",
      "Our best score is 0.9941285485465544 and has a threshold 1.03\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "df, image_paths = read_dataset()\n",
    "df, text_predictions = get_neighbors_my(df, embeddings, KNN = 100, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f166d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5229a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shoprapids",
   "language": "python",
   "name": "shoprapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
